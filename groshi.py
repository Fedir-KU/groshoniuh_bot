import os
import re
import json
import threading
import http.server
import socketserver
from datetime import datetime
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import openai
from google.cloud import vision
from google.oauth2 import service_account

# –í–∫–∞–∂—ñ—Ç—å —Ç—É—Ç –≤–∞—à chat_id (–æ—Ç—Ä–∏–º–∞–Ω–∏–π —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥—É /id)
ALLOWED_CHAT_ID = -1001234567890  # –ó–∞–º—ñ–Ω–∏ –Ω–∞ —Å–≤—ñ–π chat_id

# üõ† –§–µ–π–∫–æ–≤–∏–π HTTP-—Å–µ—Ä–≤–µ—Ä –¥–ª—è Render (—Å–ª—É—Ö–∞—î –ø–æ—Ä—Ç —ñ–∑ $PORT)
def keep_port_open():
    PORT = int(os.environ.get("PORT", "10000"))
    Handler = http.server.SimpleHTTPRequestHandler
    with socketserver.TCPServer(("", PORT), Handler) as httpd:
        print(f"Serving fake HTTP on port {PORT}")
        httpd.serve_forever()

threading.Thread(target=keep_port_open, daemon=True).start()

# üì• –ó–º—ñ–Ω–Ω—ñ –æ—Ç–æ—á–µ–Ω–Ω—è —Ç–∞ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è API –∫–ª—é—á—ñ–≤
TOKEN = os.getenv("TELEGRAM_TOKEN")
SHEET_ID = os.getenv("GOOGLE_SHEET_ID")
GOOGLE_CREDS_JSON = os.getenv("GOOGLE_CREDS_JSON")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è OpenAI
openai.api_key = OPENAI_API_KEY

# üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è Google Sheets —ñ Vision API
ecreds_dict = json.loads(GOOGLE_CREDS_JSON)
sheets_scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
sheets_creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, sheets_scope)

gspread_client = gspread.authorize(sheets_creds)
sheet = gspread_client.open_by_key(SHEET_ID).sheet1

vision_creds = service_account.Credentials.from_service_account_info(creds_dict)
vision_client = vision.ImageAnnotatorClient(credentials=vision_creds)

# üîé OCR: –≤–∏—Ç—è–≥—É—î–º–æ —Ç–µ–∫—Å—Ç –∑ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ—ñ—ó
def ocr_extract_text(image_path: str) -> str:
    with open(image_path, 'rb') as img_file:
        content = img_file.read()
    image = vision.Image(content=content)
    result = vision_client.text_detection(image=image)
    annotations = result.text_annotations
    return annotations[0].description if annotations else ''

# üß† –ü–∞—Ä—Å–∏–Ω–≥ –≤–∏—Ç—Ä–∞—Ç —á–µ—Ä–µ–∑ OpenAI GPT
def parse_expense(text: str) -> dict:
    prompt = f"""
    –í–∏–¥–æ–±–µ—Ä–∏ –∑ —Ü—å–æ–≥–æ —Ç–µ–∫—Å—Ç—É –∫–∞—Ç–µ–≥–æ—Ä—ñ—é, —Å—É–º—É (—Ü—ñ–ª–∏–º —á–∏—Å–ª–æ–º) —Ç–∞ –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å:
    "{text}"
    –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π JSON-–æ–±'—î–∫—Ç–æ–º –∑ –ø–æ–ª—è–º–∏: category, amount, description.
    """
    resp = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
    )
    return json.loads(resp.choices[0].message.content)

# –ö–æ–º–∞–Ω–¥–∞ /id: –ø–æ–≤–µ—Ä—Ç–∞—î chat_id
async def send_id(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(f"Chat ID = {update.effective_chat.id}")

# üìù –ö–æ–º–∞–Ω–¥–∞ /query: –ø—Ä–æ—Å—Ç–∏–π –∑–∞–ø–∏—Ç –¥–æ —Ç–∞–±–ª–∏—Ü—ñ —á–µ—Ä–µ–∑ GPT
async def query_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    if chat_id != ALLOWED_CHAT_ID:
        return
    query = " ".join(context.args)
    records = sheet.get_all_records()
    prompt = f"–£ –º–µ–Ω–µ —î –¥–∞–Ω—ñ –≤–∏—Ç—Ä–∞—Ç: {records}\n–ó–∞–ø–∏—Ç: {query}\n–í—ñ–¥–ø–æ–≤—ñ–¥—å —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é:" 
    resp = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
    )
    await update.message.reply_text(resp.choices[0].message.content)

# üì© –û–±—Ä–æ–±–∫–∞ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å –≤–∏—Ç—Ä–∞—Ç\async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    if chat_id != ALLOWED_CHAT_ID:
        return

    # —è–∫—â–æ —î —Ñ–æ—Ç–æ ‚Äî —Å–ø–æ—á–∞—Ç–∫—É OCR
    if update.message.photo:
        file = await context.bot.get_file(update.message.photo[-1].file_id)
        image_path = "/tmp/receipt.jpg"
        await file.download_to_drive(image_path)
        text = ocr_extract_text(image_path)
    else:
        text = update.message.text

    try:
        expense = parse_expense(text)
        cat = expense['category']
        amount = expense['amount']
        desc = expense.get('description', '').strip()
    except Exception as e:
        await update.message.reply_text("‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –≤–∏—Ç—Ä–∞—Ç—É. –°–ø—Ä–æ–±—É–π—Ç–µ —ñ–Ω—à–∏–π —Ñ–æ—Ä–º–∞—Ç –∞–±–æ —Ñ–æ—Ç–æ.")
        return

    date = datetime.now().strftime("%Y-%m-%d")
    user = update.message.from_user.first_name
    sheet.append_row([date, user, cat, amount, desc])
    await update.message.reply_text(f"‚úÖ –î–æ–¥–∞–Ω–æ: {cat} ‚Äî {amount} –≥—Ä–Ω ‚Äî {desc}")

# ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == '__main__':
    app = ApplicationBuilder().token(TOKEN).build()
    app.add_handler(CommandHandler("id", send_id))
    app.add_handler(CommandHandler("query", query_handler))
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message))
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω–æ!")
    app.run_polling()
